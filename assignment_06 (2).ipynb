{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-class classification using pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.transforms.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_data  = './'\n",
    "filename_data   = 'assignment_06_data.npz'\n",
    "data            = np.load(os.path.join(directory_data, filename_data))\n",
    "\n",
    "x_train = data['x_train']\n",
    "y_train = data['y_train']\n",
    "\n",
    "x_test  = data['x_test']\n",
    "y_test  = data['y_test']\n",
    "\n",
    "num_data_train  = x_train.shape[0]\n",
    "num_data_test   = x_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************************************\n",
      "size of x_train : (20000, 32, 32)\n",
      "size of y_train : (20000,)\n",
      "*************************************************\n",
      "size of x_test : (8000, 32, 32)\n",
      "size of y_test : (8000,)\n",
      "*************************************************\n",
      "number of training image : 20000\n",
      "height of training image : 32\n",
      "width of training image : 32\n",
      "*************************************************\n",
      "number of testing image : 8000\n",
      "height of testing image : 32\n",
      "width of testing image : 32\n",
      "*************************************************\n"
     ]
    }
   ],
   "source": [
    "print('*************************************************')\n",
    "print('size of x_train :', x_train.shape)\n",
    "print('size of y_train :', y_train.shape)\n",
    "print('*************************************************')\n",
    "print('size of x_test :', x_test.shape)\n",
    "print('size of y_test :', y_test.shape)\n",
    "print('*************************************************')\n",
    "print('number of training image :', x_train.shape[0])\n",
    "print('height of training image :', x_train.shape[1])\n",
    "print('width of training image :', x_train.shape[2])\n",
    "print('*************************************************')\n",
    "print('number of testing image :', x_test.shape[0])\n",
    "print('height of testing image :', x_test.shape[1])\n",
    "print('width of testing image :', x_test.shape[2])\n",
    "print('*************************************************')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************************************\n",
      "number of classes : 10\n",
      "*************************************************\n"
     ]
    }
   ],
   "source": [
    "print('*************************************************')\n",
    "print('number of classes :', len(set(y_train)))\n",
    "print('*************************************************')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## custom data loader for the PyTorch framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, image, label):\n",
    "        \n",
    "        self.image  = image\n",
    "        self.label  = label.astype(int)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        image   = self.image[index, :, :]\n",
    "        label   = self.label[index, ]\n",
    "\n",
    "        image   = torch.FloatTensor(image).unsqueeze(dim=0)\n",
    "        label   = torch.LongTensor([label])\n",
    "\n",
    "        return image, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        return self.image.shape[0]\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        images  = list()\n",
    "        labels  = list()\n",
    "\n",
    "        for b in batch:\n",
    "            images.append(b[0])\n",
    "            labels.append(b[1])\n",
    "\n",
    "        images  = torch.stack(images, dim=0)\n",
    "        labels  = torch.stack(labels, dim=0).squeeze()\n",
    "\n",
    "        return images, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setting device (cpu or gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## construct datasets and dataloaders for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================== \n",
    "# determine the value of the following parameter\n",
    "#\n",
    "size_minibatch      = 100\n",
    "#\n",
    "# ================================================== \n",
    "\n",
    "dataset_train       = dataset(x_train, y_train)\n",
    "dataset_test        = dataset(x_test, y_test)\n",
    "\n",
    "dataloader_train    = torch.utils.data.DataLoader(dataset_train, batch_size=size_minibatch, shuffle=True, drop_last=True, collate_fn=dataset_train.collate_fn)\n",
    "dataloader_test     = torch.utils.data.DataLoader(dataset_test, batch_size=size_minibatch, shuffle=True, drop_last=True, collate_fn=dataset_test.collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## shape of the data when using the data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label    = next(iter(dataloader_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************\n",
      "size of mini-batch of the image: torch.Size([100, 1, 32, 32])\n",
      "************************************************************\n",
      "size of mini-batch of the label: torch.Size([100])\n",
      "************************************************************\n"
     ]
    }
   ],
   "source": [
    "print('************************************************************')\n",
    "print('size of mini-batch of the image:', image.shape)\n",
    "print('************************************************************')\n",
    "print('size of mini-batch of the label:', label.shape)\n",
    "print('************************************************************')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## construct a neural network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================== \n",
    "# define the neural network architecture\n",
    "#\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "\n",
    "        self.feature    = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=2, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(in_channels=2, out_channels=4, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(in_channels=4, out_channels=8, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(32, 16, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 10, bias=True),\n",
    "        )\n",
    "\n",
    "        self.network    = nn.Sequential(\n",
    "            self.feature,\n",
    "            nn.Flatten(),\n",
    "            self.classifier,\n",
    "        )\n",
    "\n",
    "        self.initialize()\n",
    "\n",
    "\n",
    "    def initialize(self):\n",
    "\n",
    "        for m in self.network.modules():\n",
    "\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "\n",
    "                #nn.init.constant_(m.weight, 0.01)\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                nn.init.constant_(m.bias, 1)\n",
    "\n",
    "            elif isinstance(m, nn.Linear):\n",
    "    \n",
    "                #nn.init.constant_(m.weight, 0.01)\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                nn.init.constant_(m.bias, 1)\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "\n",
    "        output = self.network(input)\n",
    "\n",
    "        return output\n",
    "#\n",
    "# ================================================== "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================== \n",
    "# determine the value of the following parameter\n",
    "#\n",
    "learning_rate   = 0.1\n",
    "weight_decay    = 0.1\n",
    "#\n",
    "# ================================================== \n",
    "\n",
    "classifier      = Classifier().to(device)\n",
    "optimizer       = torch.optim.SGD(classifier.parameters(), lr=learning_rate, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier(\n",
      "  (feature): Sequential(\n",
      "    (0): Conv2d(1, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (2): ReLU()\n",
      "    (3): Conv2d(2, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): ReLU()\n",
      "    (6): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): ReLU()\n",
      "    (9): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (11): ReLU()\n",
      "    (12): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): ReLU()\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=32, out_features=16, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=16, out_features=10, bias=True)\n",
      "  )\n",
      "  (network): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(1, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): ReLU()\n",
      "      (3): Conv2d(2, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (5): ReLU()\n",
      "      (6): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (8): ReLU()\n",
      "      (9): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (11): ReLU()\n",
      "      (12): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (14): ReLU()\n",
      "    )\n",
      "    (1): Flatten(start_dim=1, end_dim=-1)\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=32, out_features=16, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=16, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compute the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_prediction(model, input):\n",
    "\n",
    "# ================================================== \n",
    "# fill up the blank\n",
    "# \n",
    "    prediction = \n",
    "#\n",
    "# ================================================== \n",
    "\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compute the loss\n",
    "- use `CrossEntropyLoss`\n",
    "- compute loss and its value (`loss.item()`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(prediction, label):\n",
    "\n",
    "# ================================================== \n",
    "# fill up the blank\n",
    "#    \n",
    " \n",
    "    loss        = \n",
    "\n",
    "#\n",
    "# ================================================== \n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compute the loss value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss_value(loss):\n",
    "    \n",
    "    loss_value = loss.item()\n",
    "    \n",
    "    return loss_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compute the accuracy\n",
    "- accuracy in percentile : 0 - 100 (%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(prediction, label):\n",
    "\n",
    "# ================================================== \n",
    "# fill up the blank\n",
    "#         \n",
    "\n",
    "    accuracy = \n",
    "\n",
    "#\n",
    "# ================================================== \n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## variables for the learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================== \n",
    "# determine the value of the following parameter\n",
    "#\n",
    "number_epoch        = 10\n",
    "#\n",
    "# ================================================== \n",
    "\n",
    "loss_train_mean     = np.zeros(number_epoch)\n",
    "loss_train_std      = np.zeros(number_epoch)\n",
    "accuracy_train_mean = np.zeros(number_epoch)\n",
    "accuracy_train_std  = np.zeros(number_epoch)\n",
    "\n",
    "loss_test_mean      = np.zeros(number_epoch)\n",
    "loss_test_std       = np.zeros(number_epoch)\n",
    "accuracy_test_mean  = np.zeros(number_epoch)\n",
    "accuracy_test_std   = np.zeros(number_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================================\n",
    "# \n",
    "# iterations for epochs\n",
    "#\n",
    "# ================================================================================\n",
    "for i in tqdm(range(number_epoch)):\n",
    "    \n",
    "    # ================================================================================\n",
    "    # \n",
    "    # training\n",
    "    #\n",
    "    # ================================================================================\n",
    "    loss_train_epoch        = []\n",
    "    accuracy_train_epoch    = []\n",
    "\n",
    "    classifier.train()\n",
    "\n",
    "    for index_batch, (image_train, label_train) in enumerate(dataloader_train):\n",
    "\n",
    "        image_train = image_train.to(device)\n",
    "        label_train = label_train.to(device)\n",
    "\n",
    "# ================================================== \n",
    "# fill up the blank\n",
    "#       \n",
    "  \n",
    "        loss_train              = \n",
    "        loss_value_train        =\n",
    "        accuracy_train          = \n",
    "        \n",
    "#\n",
    "# ================================================== \n",
    "\n",
    "        loss_train_epoch.append(loss_value_train)\n",
    "        accuracy_train_epoch.append(accuracy_train)\n",
    "\n",
    "# ================================================== \n",
    "# fill up the blank (update moodel parameters using a mini-batch)\n",
    "#       \n",
    "\n",
    "\n",
    "#\n",
    "# ==================================================  \n",
    "\n",
    "\n",
    "    loss_train_mean[i]      = np.mean(loss_train_epoch)\n",
    "    loss_train_std[i]       = np.std(loss_train_epoch)\n",
    "\n",
    "    accuracy_train_mean[i]  = np.mean(accuracy_train_epoch)\n",
    "    accuracy_train_std[i]   = np.std(accuracy_train_epoch)\n",
    "\n",
    "    # ================================================================================\n",
    "    # \n",
    "    # testing\n",
    "    #\n",
    "    # ================================================================================\n",
    "    loss_test_epoch        = []\n",
    "    accuracy_test_epoch    = []\n",
    "\n",
    "    classifier.eval()\n",
    "\n",
    "    for index_batch, (image_test, label_test) in enumerate(dataloader_test):\n",
    "\n",
    "        image_test = image_test.to(device)\n",
    "        label_test = label_test.to(device)\n",
    "\n",
    "# ================================================== \n",
    "# fill up the blank\n",
    "#         \n",
    " \n",
    "        loss_test       = \n",
    "        loss_value_test = \n",
    "        accuracy_test   = \n",
    "        \n",
    "#\n",
    "# ================================================== \n",
    " \n",
    "        loss_test_epoch.append(loss_value_test)\n",
    "        accuracy_test_epoch.append(accuracy_test)\n",
    "\n",
    "    loss_test_mean[i]      = np.mean(loss_test_epoch)\n",
    "    loss_test_std[i]       = np.std(loss_test_epoch)\n",
    "\n",
    "    accuracy_test_mean[i]  = np.mean(accuracy_test_epoch)\n",
    "    accuracy_test_std[i]   = np.std(accuracy_test_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## functions for presenting the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_result_01():\n",
    "\n",
    "    title           = 'loss (training)'\n",
    "    label_axis_x    = 'epoch' \n",
    "    label_axis_y    = 'loss'\n",
    "    color_mean      = 'red'\n",
    "    color_std       = 'blue'\n",
    "    alpha           = 0.3\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.title(title)\n",
    "\n",
    "    plt.plot(range(len(loss_train_mean)), loss_train_mean, '-', color = color_mean)\n",
    "    plt.fill_between(range(len(loss_train_mean)), loss_train_mean - loss_train_std, loss_train_mean + loss_train_std, facecolor = color_std, alpha = alpha) \n",
    "    \n",
    "    plt.xlabel(label_axis_x)\n",
    "    plt.ylabel(label_axis_y)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_result_02():\n",
    "\n",
    "    title           = 'loss (testing)'\n",
    "    label_axis_x    = 'epoch' \n",
    "    label_axis_y    = 'loss'\n",
    "    color_mean      = 'red'\n",
    "    color_std       = 'blue'\n",
    "    alpha           = 0.3\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.title(title)\n",
    "\n",
    "    plt.plot(range(len(loss_test_mean)), loss_test_mean, '-', color = color_mean)\n",
    "    plt.fill_between(range(len(loss_test_mean)), loss_test_mean - loss_test_std, loss_test_mean + loss_test_std, facecolor = color_std, alpha = alpha) \n",
    "    \n",
    "    plt.xlabel(label_axis_x)\n",
    "    plt.ylabel(label_axis_y)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_result_03():\n",
    "\n",
    "    title           = 'accuracy (training)'\n",
    "    label_axis_x    = 'epoch' \n",
    "    label_axis_y    = 'accuracy'\n",
    "    color_mean      = 'red'\n",
    "    color_std       = 'blue'\n",
    "    alpha           = 0.3\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.title(title)\n",
    "\n",
    "    plt.plot(range(len(accuracy_train_mean)), accuracy_train_mean, '-', color = color_mean)\n",
    "    plt.fill_between(range(len(accuracy_train_mean)), accuracy_train_mean - accuracy_train_std, accuracy_train_mean + accuracy_train_std, facecolor = color_std, alpha = alpha) \n",
    "    \n",
    "    plt.xlabel(label_axis_x)\n",
    "    plt.ylabel(label_axis_y)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_result_04():\n",
    "\n",
    "    title           = 'accuracy (testing)'\n",
    "    label_axis_x    = 'epoch' \n",
    "    label_axis_y    = 'accuracy'\n",
    "    color_mean      = 'red'\n",
    "    color_std       = 'blue'\n",
    "    alpha           = 0.3\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.title(title)\n",
    "\n",
    "    plt.plot(range(len(accuracy_test_mean)), accuracy_test_mean, '-', color = color_mean)\n",
    "    plt.fill_between(range(len(accuracy_test_mean)), accuracy_test_mean - accuracy_test_std, accuracy_test_mean + accuracy_test_std, facecolor = color_std, alpha = alpha) \n",
    "    \n",
    "    plt.xlabel(label_axis_x)\n",
    "    plt.ylabel(label_axis_y)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_result_05():\n",
    "\n",
    "    print('final training accuracy = %9.8f' % (accuracy_train_mean[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_result_06():\n",
    "\n",
    "    print('final testing accuracy = %9.8f' % (accuracy_test_mean[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_result = 6 \n",
    "\n",
    "for i in range(number_result):\n",
    "\n",
    "    title           = '# RESULT # {:02d}'.format(i+1) \n",
    "    name_function   = 'function_result_{:02d}()'.format(i+1)\n",
    "\n",
    "    print('') \n",
    "    print('################################################################################')\n",
    "    print('#') \n",
    "    print(title)\n",
    "    print('#') \n",
    "    print('################################################################################')\n",
    "    print('') \n",
    "\n",
    "    eval(name_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f58b7db978343697f262654c699827fe62399c751b4f1d80f455327b09615f5c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  },
  "vscode": {
   "interpreter": {
    "hash": "936d8260778fd5e616cf4743245910e0749a09bc88b1fefa5a1bd6bde9340953"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
