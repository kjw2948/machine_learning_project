{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-class classification using pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.transforms.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_data  = './'\n",
    "filename_data   = 'assignment_06_data.npz'\n",
    "data            = np.load(os.path.join(directory_data, filename_data))\n",
    "\n",
    "x_train = data['x_train']\n",
    "y_train = data['y_train']\n",
    "\n",
    "x_test  = data['x_test']\n",
    "y_test  = data['y_test']\n",
    "\n",
    "num_data_train  = x_train.shape[0]\n",
    "num_data_test   = x_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************************************\n",
      "size of x_train : (20000, 32, 32)\n",
      "size of y_train : (20000,)\n",
      "*************************************************\n",
      "size of x_test : (8000, 32, 32)\n",
      "size of y_test : (8000,)\n",
      "*************************************************\n",
      "number of training image : 20000\n",
      "height of training image : 32\n",
      "width of training image : 32\n",
      "*************************************************\n",
      "number of testing image : 8000\n",
      "height of testing image : 32\n",
      "width of testing image : 32\n",
      "*************************************************\n"
     ]
    }
   ],
   "source": [
    "print('*************************************************')\n",
    "print('size of x_train :', x_train.shape)\n",
    "print('size of y_train :', y_train.shape)\n",
    "print('*************************************************')\n",
    "print('size of x_test :', x_test.shape)\n",
    "print('size of y_test :', y_test.shape)\n",
    "print('*************************************************')\n",
    "print('number of training image :', x_train.shape[0])\n",
    "print('height of training image :', x_train.shape[1])\n",
    "print('width of training image :', x_train.shape[2])\n",
    "print('*************************************************')\n",
    "print('number of testing image :', x_test.shape[0])\n",
    "print('height of testing image :', x_test.shape[1])\n",
    "print('width of testing image :', x_test.shape[2])\n",
    "print('*************************************************')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************************************\n",
      "number of classes : 10\n",
      "*************************************************\n"
     ]
    }
   ],
   "source": [
    "print('*************************************************')\n",
    "print('number of classes :', len(set(y_train)))\n",
    "print('*************************************************')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## custom data loader for the PyTorch framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, image, label):\n",
    "        \n",
    "        self.image  = image\n",
    "        self.label  = label.astype(int)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        image   = self.image[index, :, :]\n",
    "        label   = self.label[index, ]\n",
    "\n",
    "        image   = torch.FloatTensor(image).unsqueeze(dim=0)\n",
    "        label   = torch.LongTensor([label])\n",
    "\n",
    "        return image, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        return self.image.shape[0]\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        images  = list()\n",
    "        labels  = list()\n",
    "\n",
    "        for b in batch:\n",
    "            images.append(b[0])\n",
    "            labels.append(b[1])\n",
    "\n",
    "        images  = torch.stack(images, dim=0)\n",
    "        labels  = torch.stack(labels, dim=0).squeeze()\n",
    "\n",
    "        return images, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setting device (cpu or gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## construct datasets and dataloaders for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================== \n",
    "# determine the value of the following parameter\n",
    "#\n",
    "size_minibatch      = 100\n",
    "#\n",
    "# ================================================== \n",
    "\n",
    "dataset_train       = dataset(x_train, y_train)\n",
    "dataset_test        = dataset(x_test, y_test)\n",
    "\n",
    "dataloader_train    = torch.utils.data.DataLoader(dataset_train, batch_size=size_minibatch, shuffle=True, drop_last=True, collate_fn=dataset_train.collate_fn)\n",
    "dataloader_test     = torch.utils.data.DataLoader(dataset_test, batch_size=size_minibatch, shuffle=True, drop_last=True, collate_fn=dataset_test.collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## shape of the data when using the data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label    = next(iter(dataloader_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************\n",
      "size of mini-batch of the image: torch.Size([100, 1, 32, 32])\n",
      "************************************************************\n",
      "size of mini-batch of the label: torch.Size([100])\n",
      "************************************************************\n"
     ]
    }
   ],
   "source": [
    "print('************************************************************')\n",
    "print('size of mini-batch of the image:', image.shape)\n",
    "print('************************************************************')\n",
    "print('size of mini-batch of the label:', label.shape)\n",
    "print('************************************************************')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## construct a neural network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================== \n",
    "# define the neural network architecture\n",
    "#\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "\n",
    "        self.feature    = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=2, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(in_channels=2, out_channels=4, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(in_channels=4, out_channels=8, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(32, 16, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 10, bias=True),\n",
    "        )\n",
    "\n",
    "        self.network    = nn.Sequential(\n",
    "            self.feature,\n",
    "            nn.Flatten(),\n",
    "            self.classifier,\n",
    "        )\n",
    "\n",
    "        self.initialize()\n",
    "\n",
    "\n",
    "    def initialize(self):\n",
    "\n",
    "        for m in self.network.modules():\n",
    "\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "\n",
    "                #nn.init.constant_(m.weight, 0.01)\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                nn.init.constant_(m.bias, 1)\n",
    "\n",
    "            elif isinstance(m, nn.Linear):\n",
    "    \n",
    "                #nn.init.constant_(m.weight, 0.01)\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                nn.init.constant_(m.bias, 1)\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "\n",
    "        output = self.network(input)\n",
    "\n",
    "        return output\n",
    "#\n",
    "# ================================================== "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================== \n",
    "# determine the value of the following parameter\n",
    "#\n",
    "learning_rate   = 0.1\n",
    "weight_decay    = 0.1\n",
    "#\n",
    "# ================================================== \n",
    "\n",
    "classifier      = Classifier().to(device)\n",
    "optimizer       = torch.optim.SGD(classifier.parameters(), lr=learning_rate, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier(\n",
      "  (feature): Sequential(\n",
      "    (0): Conv2d(1, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (2): ReLU()\n",
      "    (3): Conv2d(2, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): ReLU()\n",
      "    (6): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): ReLU()\n",
      "    (9): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (11): ReLU()\n",
      "    (12): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): ReLU()\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=32, out_features=16, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=16, out_features=10, bias=True)\n",
      "  )\n",
      "  (network): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(1, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (2): ReLU()\n",
      "      (3): Conv2d(2, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (5): ReLU()\n",
      "      (6): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (8): ReLU()\n",
      "      (9): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (11): ReLU()\n",
      "      (12): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (14): ReLU()\n",
      "    )\n",
      "    (1): Flatten(start_dim=1, end_dim=-1)\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=32, out_features=16, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=16, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compute the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_prediction(model, input):\n",
    "\n",
    "# ================================================== \n",
    "# fill up the blank\n",
    "# \n",
    "    prediction = model(input)\n",
    "#\n",
    "# ================================================== \n",
    "\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compute the loss\n",
    "- use `CrossEntropyLoss`\n",
    "- compute loss and its value (`loss.item()`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(prediction, label):\n",
    "\n",
    "# ================================================== \n",
    "# fill up the blank\n",
    "#    \n",
    "    cross_entrophy = torch.nn.CrossEntropyLoss()\n",
    "    loss        = cross_entrophy(prediction, label)\n",
    "\n",
    "#\n",
    "# ================================================== \n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compute the loss value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss_value(loss):\n",
    "    \n",
    "    loss_value = loss.item()\n",
    "    \n",
    "    return loss_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compute the accuracy\n",
    "- accuracy in percentile : 0 - 100 (%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(prediction, label):\n",
    "\n",
    "# ================================================== \n",
    "# fill up the blank\n",
    "#         \n",
    "    num_data = label.shape[0]\n",
    "    \n",
    "    compare_prediction_label = np.argmax(prediction,axis =1) == np.argmax(label,axis =1) \n",
    "    accuracy = np.count_nonzero(compare_prediction_label == True) * 100 / num_data \n",
    "\n",
    "#\n",
    "# ================================================== \n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## variables for the learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================== \n",
    "# determine the value of the following parameter\n",
    "#\n",
    "number_epoch        = 10\n",
    "#\n",
    "# ================================================== \n",
    "\n",
    "loss_train_mean     = np.zeros(number_epoch)\n",
    "loss_train_std      = np.zeros(number_epoch)\n",
    "accuracy_train_mean = np.zeros(number_epoch)\n",
    "accuracy_train_std  = np.zeros(number_epoch)\n",
    "\n",
    "loss_test_mean      = np.zeros(number_epoch)\n",
    "loss_test_std       = np.zeros(number_epoch)\n",
    "accuracy_test_mean  = np.zeros(number_epoch)\n",
    "accuracy_test_std   = np.zeros(number_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: argmax() got an unexpected keyword argument 'axis'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m         loss_train              \u001b[38;5;241m=\u001b[39m compute_loss(compute_prediction(classifier, image_train), label_train)\n\u001b[1;32m     28\u001b[0m         loss_value_train        \u001b[38;5;241m=\u001b[39m compute_loss_value(loss_train)\n\u001b[0;32m---> 29\u001b[0m         accuracy_train          \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_accuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompute_prediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclassifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# ================================================== \u001b[39;00m\n\u001b[1;32m     34\u001b[0m         loss_train_epoch\u001b[38;5;241m.\u001b[39mappend(loss_value_train)\n",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36mcompute_accuracy\u001b[0;34m(prediction, label)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_accuracy\u001b[39m(prediction, label):\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# ================================================== \u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# fill up the blank\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#         \u001b[39;00m\n\u001b[1;32m      6\u001b[0m     num_data \u001b[38;5;241m=\u001b[39m label\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m----> 8\u001b[0m     compare_prediction_label \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(label,axis \u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \n\u001b[1;32m      9\u001b[0m     accuracy \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcount_nonzero(compare_prediction_label \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m/\u001b[39m num_data \n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# ================================================== \u001b[39;00m\n",
      "File \u001b[0;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36margmax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:1195\u001b[0m, in \u001b[0;36margmax\u001b[0;34m(a, axis, out)\u001b[0m\n\u001b[1;32m   1121\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_argmax_dispatcher)\n\u001b[1;32m   1122\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21margmax\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1123\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;124;03m    Returns the indices of the maximum values along an axis.\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1193\u001b[0m \n\u001b[1;32m   1194\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1195\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43margmax\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:66\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bound(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:43\u001b[0m, in \u001b[0;36m_wrapit\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m     wrap \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m, method)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wrap:\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, mu\u001b[38;5;241m.\u001b[39mndarray):\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/_tensor.py:757\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m__array__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    756\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 757\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    758\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    759\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    }
   ],
   "source": [
    "# ================================================================================\n",
    "# \n",
    "# iterations for epochs\n",
    "#\n",
    "# ================================================================================\n",
    "for i in tqdm(range(number_epoch)):\n",
    "    \n",
    "    # ================================================================================\n",
    "    # \n",
    "    # training\n",
    "    #\n",
    "    # ================================================================================\n",
    "    loss_train_epoch        = []\n",
    "    accuracy_train_epoch    = []\n",
    "\n",
    "    classifier.train()\n",
    "\n",
    "    for index_batch, (image_train, label_train) in enumerate(dataloader_train):\n",
    "\n",
    "        image_train = image_train.to(device)\n",
    "        label_train = label_train.to(device)\n",
    "\n",
    "# ================================================== \n",
    "# fill up the blank\n",
    "#       \n",
    "  \n",
    "        loss_train              = compute_loss(compute_prediction(classifier, image_train), label_train)\n",
    "        loss_value_train        = compute_loss_value(loss_train)\n",
    "        accuracy_train          = compute_accuracy(compute_prediction(classifier, image_train), label_train)\n",
    "        \n",
    "#\n",
    "# ================================================== \n",
    "\n",
    "        loss_train_epoch.append(loss_value_train)\n",
    "        accuracy_train_epoch.append(accuracy_train)\n",
    "\n",
    "# ================================================== \n",
    "# fill up the blank (update moodel parameters using a mini-batch)\n",
    "#       \n",
    "        weight_decay = optimizer.zero_grad()\n",
    "\n",
    "#\n",
    "# ==================================================  \n",
    "\n",
    "\n",
    "    loss_train_mean[i]      = np.mean(loss_train_epoch)\n",
    "    loss_train_std[i]       = np.std(loss_train_epoch)\n",
    "\n",
    "    accuracy_train_mean[i]  = np.mean(accuracy_train_epoch)\n",
    "    accuracy_train_std[i]   = np.std(accuracy_train_epoch)\n",
    "\n",
    "    # ================================================================================\n",
    "    # \n",
    "    # testing\n",
    "    #\n",
    "    # ================================================================================\n",
    "    loss_test_epoch        = []\n",
    "    accuracy_test_epoch    = []\n",
    "\n",
    "    classifier.eval()\n",
    "\n",
    "    for index_batch, (image_test, label_test) in enumerate(dataloader_test):\n",
    "\n",
    "        image_test = image_test.to(device)\n",
    "        label_test = label_test.to(device)\n",
    "\n",
    "# ================================================== \n",
    "# fill up the blank\n",
    "#         \n",
    " \n",
    "        loss_test       = compute_loss(compute_prediction(classifier, image_test), label_test)\n",
    "        loss_value_test = compute_loss_value(loss_test)\n",
    "        accuracy_test   =  compute_accuracy(compute_prediction(classifier, image_test), label_test)\n",
    "         \n",
    "        \n",
    "        \n",
    "#\n",
    "# ================================================== \n",
    " \n",
    "        loss_test_epoch.append(loss_value_test)\n",
    "        accuracy_test_epoch.append(accuracy_test)\n",
    "\n",
    "    loss_test_mean[i]      = np.mean(loss_test_epoch)\n",
    "    loss_test_std[i]       = np.std(loss_test_epoch)\n",
    "\n",
    "    accuracy_test_mean[i]  = np.mean(accuracy_test_epoch)\n",
    "    accuracy_test_std[i]   = np.std(accuracy_test_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## functions for presenting the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_result_01():\n",
    "\n",
    "    title           = 'loss (training)'\n",
    "    label_axis_x    = 'epoch' \n",
    "    label_axis_y    = 'loss'\n",
    "    color_mean      = 'red'\n",
    "    color_std       = 'blue'\n",
    "    alpha           = 0.3\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.title(title)\n",
    "\n",
    "    plt.plot(range(len(loss_train_mean)), loss_train_mean, '-', color = color_mean)\n",
    "    plt.fill_between(range(len(loss_train_mean)), loss_train_mean - loss_train_std, loss_train_mean + loss_train_std, facecolor = color_std, alpha = alpha) \n",
    "    \n",
    "    plt.xlabel(label_axis_x)\n",
    "    plt.ylabel(label_axis_y)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_result_02():\n",
    "\n",
    "    title           = 'loss (testing)'\n",
    "    label_axis_x    = 'epoch' \n",
    "    label_axis_y    = 'loss'\n",
    "    color_mean      = 'red'\n",
    "    color_std       = 'blue'\n",
    "    alpha           = 0.3\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.title(title)\n",
    "\n",
    "    plt.plot(range(len(loss_test_mean)), loss_test_mean, '-', color = color_mean)\n",
    "    plt.fill_between(range(len(loss_test_mean)), loss_test_mean - loss_test_std, loss_test_mean + loss_test_std, facecolor = color_std, alpha = alpha) \n",
    "    \n",
    "    plt.xlabel(label_axis_x)\n",
    "    plt.ylabel(label_axis_y)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_result_03():\n",
    "\n",
    "    title           = 'accuracy (training)'\n",
    "    label_axis_x    = 'epoch' \n",
    "    label_axis_y    = 'accuracy'\n",
    "    color_mean      = 'red'\n",
    "    color_std       = 'blue'\n",
    "    alpha           = 0.3\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.title(title)\n",
    "\n",
    "    plt.plot(range(len(accuracy_train_mean)), accuracy_train_mean, '-', color = color_mean)\n",
    "    plt.fill_between(range(len(accuracy_train_mean)), accuracy_train_mean - accuracy_train_std, accuracy_train_mean + accuracy_train_std, facecolor = color_std, alpha = alpha) \n",
    "    \n",
    "    plt.xlabel(label_axis_x)\n",
    "    plt.ylabel(label_axis_y)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_result_04():\n",
    "\n",
    "    title           = 'accuracy (testing)'\n",
    "    label_axis_x    = 'epoch' \n",
    "    label_axis_y    = 'accuracy'\n",
    "    color_mean      = 'red'\n",
    "    color_std       = 'blue'\n",
    "    alpha           = 0.3\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.title(title)\n",
    "\n",
    "    plt.plot(range(len(accuracy_test_mean)), accuracy_test_mean, '-', color = color_mean)\n",
    "    plt.fill_between(range(len(accuracy_test_mean)), accuracy_test_mean - accuracy_test_std, accuracy_test_mean + accuracy_test_std, facecolor = color_std, alpha = alpha) \n",
    "    \n",
    "    plt.xlabel(label_axis_x)\n",
    "    plt.ylabel(label_axis_y)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_result_05():\n",
    "\n",
    "    print('final training accuracy = %9.8f' % (accuracy_train_mean[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_result_06():\n",
    "\n",
    "    print('final testing accuracy = %9.8f' % (accuracy_test_mean[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_result = 6 \n",
    "\n",
    "for i in range(number_result):\n",
    "\n",
    "    title           = '# RESULT # {:02d}'.format(i+1) \n",
    "    name_function   = 'function_result_{:02d}()'.format(i+1)\n",
    "\n",
    "    print('') \n",
    "    print('################################################################################')\n",
    "    print('#') \n",
    "    print(title)\n",
    "    print('#') \n",
    "    print('################################################################################')\n",
    "    print('') \n",
    "\n",
    "    eval(name_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f58b7db978343697f262654c699827fe62399c751b4f1d80f455327b09615f5c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  },
  "vscode": {
   "interpreter": {
    "hash": "936d8260778fd5e616cf4743245910e0749a09bc88b1fefa5a1bd6bde9340953"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
